{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c80351",
   "metadata": {},
   "source": [
    "## This notebook Focuses on Super learner and Stacking concept in Deep learning\n",
    "\n",
    "> So you might be wondering what is `super Learner` Since Stacking is some what like already covered on previous notebook although there are also some hint of super Learner earlier but let's first start with Super Learner\n",
    "\n",
    "### [`Super Learner`](https://machinelearningmastery.com/super-learner-ensemble-in-python/)\n",
    "\n",
    "*Consider that you have already fit many different algorithms on your dataset, and some algorithms have been evaluated many times with different configurations. You may have many tens or hundreds of different models of your problem. Why not use all those models instead of the best model from the group?*\n",
    "\n",
    "This is the intuition behind the so-called `super learner` ensemble algorithm.\n",
    "\n",
    ">The super learner algorithm was proposed by Mark van der Laan, Eric Polley, and Alan Hubbard from Berkeley in their 2007 paper titled “Super Learner.” It was published in a biological journal, which may be sheltered from the broader machine learning community.\n",
    "\n",
    "**The super learner algorithm involves first pre-defining the k-fold split of your data, then evaluating all different algorithms and algorithm configurations on the same split of the data. All out-of-fold predictions are then kept and used to train an algorithm that learns how to best combine the predictions.**\n",
    "\n",
    "### The procedure can be summarized as follow: \n",
    "\n",
    "1. Select a k-fold split of the training dataset.\n",
    "2. Select m base-models or model configurations.\n",
    "3. For each basemodel:\n",
    "    * Evaluate using k-fold cross-validation.\n",
    "    * Store all out-of-fold predictions.\n",
    "    * Fit the model on the full training dataset and store.\n",
    "4. Fit a meta-model on the out-of-fold predictions.\n",
    "5. Evaluate the model on a holdout dataset or use model to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12465e",
   "metadata": {},
   "source": [
    "![superlearner](Super-learner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba27665d",
   "metadata": {},
   "source": [
    "#### Super Learner is an application of Stacking Generalization *from previous notebooks*\n",
    "\n",
    "*firstly*\n",
    "\n",
    "## Super Learner for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89424245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually Develop a Super Learner with scikit learn\n",
    "\n",
    "#Importing all modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb80fb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data \n",
    "housing = fetch_california_housing()\n",
    "housing_df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "housing_df['target'] = housing.target\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df312974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "88b87c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get features and labels \n",
    "X = housing_df.drop(\"target\",axis = 1)\n",
    "y = housing_df.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2c6aa1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of all base model\n",
    "def get_models(): \n",
    "    models = []\n",
    "    models.append(LinearRegression())\n",
    "    models.append(ElasticNet())\n",
    "    models.append(SVR(gamma = 'scale'))\n",
    "    models.append(DecisionTreeRegressor())\n",
    "    models.append(KNeighborsRegressor())\n",
    "    models.append(AdaBoostRegressor())\n",
    "    models.append(BaggingRegressor(n_estimators=10))\n",
    "    models.append(RandomForestRegressor(n_estimators=10))\n",
    "    models.append(ExtraTreesRegressor(n_estimators = 10))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73683cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 20637 20638 20639]\n",
      "  Test:  index=[   14    27    32 ... 20605 20611 20634]\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     3 ... 20637 20638 20639]\n",
      "  Test:  index=[    2     8    21 ... 20575 20584 20588]\n",
      "Fold 2:\n",
      "  Train: index=[    0     1     2 ... 20635 20636 20639]\n",
      "  Test:  index=[    3    15    22 ... 20618 20637 20638]\n",
      "Fold 3:\n",
      "  Train: index=[    0     1     2 ... 20637 20638 20639]\n",
      "  Test:  index=[   13    43    51 ... 20590 20613 20629]\n",
      "Fold 4:\n",
      "  Train: index=[    0     2     3 ... 20637 20638 20639]\n",
      "  Test:  index=[    1     7    34 ... 20622 20625 20627]\n",
      "Fold 5:\n",
      "  Train: index=[    0     1     2 ... 20637 20638 20639]\n",
      "  Test:  index=[    9    10    12 ... 20612 20615 20620]\n",
      "Fold 6:\n",
      "  Train: index=[    1     2     3 ... 20637 20638 20639]\n",
      "  Test:  index=[    0     4     5 ... 20621 20623 20632]\n",
      "Fold 7:\n",
      "  Train: index=[    0     1     2 ... 20636 20637 20638]\n",
      "  Test:  index=[   19    24    28 ... 20624 20630 20639]\n",
      "Fold 8:\n",
      "  Train: index=[    0     1     2 ... 20637 20638 20639]\n",
      "  Test:  index=[   16    29    38 ... 20633 20635 20636]\n",
      "Fold 9:\n",
      "  Train: index=[    0     1     2 ... 20637 20638 20639]\n",
      "  Test:  index=[   11    23    26 ... 20619 20626 20628]\n"
     ]
    }
   ],
   "source": [
    "# Creating k fold for dataset for 10 folds \n",
    "kfold = KFold(n_splits = 10, shuffle = True)\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9b37446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16512, 8), (4128, 8), (16512,), (4128,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spliting the data into train and test split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5637ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaking down function\n",
    "a = np.array([32,232,23,23,21,12,123,234])\n",
    "b = np.array([323,32,32,23,3223,32,32,12])\n",
    "a_reshaped = a.reshape(len(a),1)\n",
    "b_reshaped = b.reshape(len(b),1)\n",
    "a_hstack = []\n",
    "a_hstack.append(np.hstack(a_reshaped))\n",
    "a_vhstack = [] \n",
    "a_vhstack.append(np.vstack(a_hstack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f7353e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 32, 232,  23,  23,  21,  12, 123, 234]),\n",
       " array([[ 32],\n",
       "        [232],\n",
       "        [ 23],\n",
       "        [ 23],\n",
       "        [ 21],\n",
       "        [ 12],\n",
       "        [123],\n",
       "        [234]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, a_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc30723a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([ 32, 232,  23,  23,  21,  12, 123, 234])], (8,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_hstack, a_hstack[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "caafe3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 32, 232,  23,  23,  21,  12, 123, 234]])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " a_vhstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "16db3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hstack.append(np.hstack(b_reshaped))\n",
    "a_vhstack.append(np.vstack(a_hstack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b1d86db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([ 32, 232,  23,  23,  21,  12, 123, 234]),\n",
       "  array([ 323,   32,   32,   23, 3223,   32,   32,   12])],\n",
       " [array([[ 32, 232,  23,  23,  21,  12, 123, 234]]),\n",
       "  array([[  32,  232,   23,   23,   21,   12,  123,  234],\n",
       "         [ 323,   32,   32,   23, 3223,   32,   32,   12]])])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_hstack, a_vhstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "258df209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect prediction of each base model on k fold dataset\n",
    "def get_out_of_fold_predictions(X,y,models): \n",
    "    meta_X, meta_y = list(), list() # this are going to act as input for meta model\n",
    "    #define split of data \n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    #enumerate splits \n",
    "    for train_index,test_index in kfold.split(X):\n",
    "        fold_predictions = list()\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        meta_y.extend(y_test)\n",
    "        \n",
    "        #fit and make predictions with each base-model\n",
    "        for model in models:\n",
    "            model.fit(X_train,y_train)\n",
    "            base_model_prediction = model.predict(X_test)\n",
    "            \n",
    "            fold_predictions.append(base_model_prediction.reshape(len(base_model_prediction),1))\n",
    "        meta_X.append(np.hstack(fold_predictions))\n",
    "    return np.vstack(meta_X), np.asarray(meta_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d26b610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.7660686 , 1.82273782, 1.81112003, ..., 2.0053    , 2.1713    ,\n",
       "         1.6605    ],\n",
       "        [1.7839361 , 1.86237395, 1.80123518, ..., 1.7426    , 1.8851    ,\n",
       "         1.7762    ],\n",
       "        [2.18013872, 1.73304683, 1.82377491, ..., 2.337     , 2.3666    ,\n",
       "         2.3146    ],\n",
       "        ...,\n",
       "        [1.79198967, 1.78242079, 1.79856318, ..., 1.6777    , 1.7894    ,\n",
       "         1.4824    ],\n",
       "        [2.33888768, 2.41281997, 1.94047055, ..., 2.6328    , 2.728101  ,\n",
       "         2.625     ],\n",
       "        [2.01936282, 1.80689836, 1.88501851, ..., 3.769904  , 2.940702  ,\n",
       "         4.197306  ]]),\n",
       " array([1.577, 1.535, 2.281, ..., 1.271, 3.203, 4.25 ]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how inputs of meta data are goona look like\n",
    "meta_X, meta_y = get_out_of_fold_predictions(X_train,y_train,models=get_models())\n",
    "meta_X, meta_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4be2f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16512, 9), (16512,))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of meta data shows now they can be used as input for any model\n",
    "meta_X.shape, meta_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c88c01b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.766069</td>\n",
       "      <td>1.822738</td>\n",
       "      <td>1.811120</td>\n",
       "      <td>2.750</td>\n",
       "      <td>1.750600</td>\n",
       "      <td>2.300209</td>\n",
       "      <td>2.005300</td>\n",
       "      <td>2.171300</td>\n",
       "      <td>1.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.783936</td>\n",
       "      <td>1.862374</td>\n",
       "      <td>1.801235</td>\n",
       "      <td>1.500</td>\n",
       "      <td>2.114200</td>\n",
       "      <td>1.935461</td>\n",
       "      <td>1.742600</td>\n",
       "      <td>1.885100</td>\n",
       "      <td>1.776200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.180139</td>\n",
       "      <td>1.733047</td>\n",
       "      <td>1.823775</td>\n",
       "      <td>2.308</td>\n",
       "      <td>2.682400</td>\n",
       "      <td>1.884963</td>\n",
       "      <td>2.337000</td>\n",
       "      <td>2.366600</td>\n",
       "      <td>2.314600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.063799</td>\n",
       "      <td>2.169576</td>\n",
       "      <td>1.775397</td>\n",
       "      <td>1.591</td>\n",
       "      <td>1.868200</td>\n",
       "      <td>2.779841</td>\n",
       "      <td>1.639100</td>\n",
       "      <td>1.584800</td>\n",
       "      <td>1.599800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.651970</td>\n",
       "      <td>1.725596</td>\n",
       "      <td>1.855109</td>\n",
       "      <td>3.603</td>\n",
       "      <td>2.221402</td>\n",
       "      <td>2.782794</td>\n",
       "      <td>2.205600</td>\n",
       "      <td>2.783100</td>\n",
       "      <td>2.497700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16507</th>\n",
       "      <td>2.001309</td>\n",
       "      <td>2.002026</td>\n",
       "      <td>1.788406</td>\n",
       "      <td>1.449</td>\n",
       "      <td>1.499400</td>\n",
       "      <td>2.010944</td>\n",
       "      <td>1.244600</td>\n",
       "      <td>1.188400</td>\n",
       "      <td>1.324300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16508</th>\n",
       "      <td>1.132998</td>\n",
       "      <td>1.773183</td>\n",
       "      <td>1.850860</td>\n",
       "      <td>0.982</td>\n",
       "      <td>1.421800</td>\n",
       "      <td>1.706269</td>\n",
       "      <td>1.174200</td>\n",
       "      <td>1.041200</td>\n",
       "      <td>0.816100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16509</th>\n",
       "      <td>1.791990</td>\n",
       "      <td>1.782421</td>\n",
       "      <td>1.798563</td>\n",
       "      <td>1.703</td>\n",
       "      <td>1.268600</td>\n",
       "      <td>2.271499</td>\n",
       "      <td>1.677700</td>\n",
       "      <td>1.789400</td>\n",
       "      <td>1.482400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16510</th>\n",
       "      <td>2.338888</td>\n",
       "      <td>2.412820</td>\n",
       "      <td>1.940471</td>\n",
       "      <td>3.215</td>\n",
       "      <td>3.183202</td>\n",
       "      <td>3.019157</td>\n",
       "      <td>2.632800</td>\n",
       "      <td>2.728101</td>\n",
       "      <td>2.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16511</th>\n",
       "      <td>2.019363</td>\n",
       "      <td>1.806898</td>\n",
       "      <td>1.885019</td>\n",
       "      <td>2.338</td>\n",
       "      <td>2.093000</td>\n",
       "      <td>3.030168</td>\n",
       "      <td>3.769904</td>\n",
       "      <td>2.940702</td>\n",
       "      <td>4.197306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16512 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2      3         4         5         6  \\\n",
       "0      1.766069  1.822738  1.811120  2.750  1.750600  2.300209  2.005300   \n",
       "1      1.783936  1.862374  1.801235  1.500  2.114200  1.935461  1.742600   \n",
       "2      2.180139  1.733047  1.823775  2.308  2.682400  1.884963  2.337000   \n",
       "3      2.063799  2.169576  1.775397  1.591  1.868200  2.779841  1.639100   \n",
       "4      1.651970  1.725596  1.855109  3.603  2.221402  2.782794  2.205600   \n",
       "...         ...       ...       ...    ...       ...       ...       ...   \n",
       "16507  2.001309  2.002026  1.788406  1.449  1.499400  2.010944  1.244600   \n",
       "16508  1.132998  1.773183  1.850860  0.982  1.421800  1.706269  1.174200   \n",
       "16509  1.791990  1.782421  1.798563  1.703  1.268600  2.271499  1.677700   \n",
       "16510  2.338888  2.412820  1.940471  3.215  3.183202  3.019157  2.632800   \n",
       "16511  2.019363  1.806898  1.885019  2.338  2.093000  3.030168  3.769904   \n",
       "\n",
       "              7         8  \n",
       "0      2.171300  1.660500  \n",
       "1      1.885100  1.776200  \n",
       "2      2.366600  2.314600  \n",
       "3      1.584800  1.599800  \n",
       "4      2.783100  2.497700  \n",
       "...         ...       ...  \n",
       "16507  1.188400  1.324300  \n",
       "16508  1.041200  0.816100  \n",
       "16509  1.789400  1.482400  \n",
       "16510  2.728101  2.625000  \n",
       "16511  2.940702  4.197306  \n",
       "\n",
       "[16512 rows x 9 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame representation of X_meta for better understanding\n",
    "pd.DataFrame(meta_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "068f3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a funtion to fit base model\n",
    "def fit_base_models(X,y,models): \n",
    "    for model in models: \n",
    "        model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "672aa69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to fit meta model\n",
    "def fit_meta_model(X,y): \n",
    "    model = LinearRegression() # using Linear Regression for meta model since meta models are generally simple models\n",
    "    model.fit(X,y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab3389",
   "metadata": {},
   "source": [
    "### Before fitting the model let's Create evaluation function for both base model and meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fea16abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X,y,models): \n",
    "    for model in models:\n",
    "        y_preds = model.predict(X)\n",
    "        mse =mean_squared_error(y,y_preds)\n",
    "        print(\"%s: RMSE %.3f\"%(model.__class__.__name__,np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71f40cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_learner_predictions(X,models,meta_model): \n",
    "    meta_X = list()\n",
    "    for model in models: \n",
    "        y_preds = model.predict(X)\n",
    "        meta_X.append(y_preds.reshape(len(y_preds),1))\n",
    "    meta_X = np.hstack(meta_X)\n",
    "        \n",
    "    #predict\n",
    "    return meta_model.predict(meta_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32d3da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_model_evaluate(y_test,y_preds): \n",
    "    print(\"Super Learner :RMSE %.3f\" % (np.sqrt(mean_squared_error(y_test,y_preds))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2b801",
   "metadata": {},
   "source": [
    "## Let's fit the models and `our Super Learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0988ebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting base models...\n",
      "fitting Meta model...\n"
     ]
    }
   ],
   "source": [
    "models = get_models()\n",
    "print(\"fitting base models...\")\n",
    "fit_base_models(X_train,y_train,models)\n",
    "print(\"fitting Meta model...\")\n",
    "meta_model = fit_meta_model(meta_X,meta_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f9f63d",
   "metadata": {},
   "source": [
    "## Let's evaluate our models and See results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78fa32ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: RMSE 0.722\n",
      "ElasticNet: RMSE 0.881\n",
      "SVR: RMSE 1.162\n",
      "DecisionTreeRegressor: RMSE 0.685\n",
      "KNeighborsRegressor: RMSE 1.044\n",
      "AdaBoostRegressor: RMSE 0.873\n",
      "BaggingRegressor: RMSE 0.519\n",
      "RandomForestRegressor: RMSE 0.515\n",
      "ExtraTreesRegressor: RMSE 0.523\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(X_test,y_test,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "00308fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4128,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_super_learner = super_learner_predictions(X_test,models,meta_model)\n",
    "y_preds_super_learner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a88223a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4128,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a38633e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super Learner :RMSE 0.488\n"
     ]
    }
   ],
   "source": [
    "meta_model_evaluate(y_test,y_preds_super_learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d3f30",
   "metadata": {},
   "source": [
    "# As we can see Super Learner has least `RMSE = 0.488` means it is the best of all models\n",
    "\n",
    "**This is what we called `super learner` which can learn from all models and provide us the best way to combine all this model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81bcdd",
   "metadata": {},
   "source": [
    "### you can also implement this with `ML-Ensemble Library`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ef80c",
   "metadata": {},
   "source": [
    "*for this we need mlens library*\n",
    "\n",
    "> pip install mlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f42785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
